{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPHs5DMVG4FgTX5YGo9cHIH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salmon1605/Lizadon1006/blob/main/TrojViT_2_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qLS4L7QpCr6",
        "outputId": "8ddce8cb-bad1-4743-cc3d-bc5e47821247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TrojViT'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 69 (delta 15), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (69/69), 65.78 KiB | 547.00 KiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mxzheng/TrojViT.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd TrojViT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Wke8Q1pKQj",
        "outputId": "d6574695-d043-47d6-c4f8-0af07c98f52f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TrojViT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install transformers\n",
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-eS_FSlpMyT",
        "outputId": "c97baa4f-eabc-4370-c8b6-cd60fe702a14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.5.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSVaEcHbpYA9",
        "outputId": "73ff74cb-f3e9-4690-ad76-df3c6d6b6b28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main_patch_vit.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5yQCbSTpcy4",
        "outputId": "3e5ea174-6c93-45dd-9ebc-83de3c299872"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/content/TrojViT/models/DeiT.py:61: UserWarning: Overwriting deit_tiny_patch16_224 in registry with models.DeiT.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_tiny_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:76: UserWarning: Overwriting deit_small_patch16_224 in registry with models.DeiT.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_small_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:91: UserWarning: Overwriting deit_base_patch16_224 in registry with models.DeiT.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:106: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with models.DeiT.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:121: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with models.DeiT.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_small_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:136: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with models.DeiT.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:151: UserWarning: Overwriting deit_base_patch16_384 in registry with models.DeiT.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_patch16_384(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:166: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with models.DeiT.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_distilled_patch16_384(pretrained=False, **kwargs):\n",
            "model.safetensors: 100% 346M/346M [00:01<00:00, 178MB/s]\n",
            "86567656\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/TrojViT/main_patch_vit.py\", line 559, in <module>\n",
            "    main()\n",
            "  File \"/content/TrojViT/main_patch_vit.py\", line 215, in main\n",
            "    loader = get_loaders(args)\n",
            "  File \"/content/TrojViT/utils.py\", line 32, in get_loaders\n",
            "    val_dataset = datasets.ImageFolder(valdir,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\", line 328, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\", line 149, in __init__\n",
            "    classes, class_to_idx = self.find_classes(self.root)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\", line 234, in find_classes\n",
            "    return find_classes(directory)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\", line 41, in find_classes\n",
            "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/mnt/mdata/new/imagenet/val'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main_patch_vit.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmhx1W2Rp_G_",
        "outputId": "0ee2855f-d3ee-4470-fd64-a241c163e280"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/content/TrojViT/models/DeiT.py:61: UserWarning: Overwriting deit_tiny_patch16_224 in registry with models.DeiT.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_tiny_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:76: UserWarning: Overwriting deit_small_patch16_224 in registry with models.DeiT.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_small_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:91: UserWarning: Overwriting deit_base_patch16_224 in registry with models.DeiT.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:106: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with models.DeiT.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:121: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with models.DeiT.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_small_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:136: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with models.DeiT.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:151: UserWarning: Overwriting deit_base_patch16_384 in registry with models.DeiT.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_patch16_384(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:166: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with models.DeiT.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_distilled_patch16_384(pretrained=False, **kwargs):\n",
            "Tiny ImageNet already downloaded!\n",
            "Tiny ImageNet already extracted!\n",
            "Processing Tiny ImageNet validation dataset...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/TrojViT/main_patch_vit.py\", line 90, in <module>\n",
            "    os.rename(img_src, img_dst)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/tiny-imagenet-200/val/images/val_0.JPEG' -> '/mnt/mdata/new/imagenet/val/n03444034/val_0.JPEG'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/tiny-imagenet-200/val/images/\n",
        "!head /content/tiny-imagenet-200/val/val_annotations.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2DMntnvr1g5",
        "outputId": "17e9575c-0d8c-4497-de7e-21cdbbc5d38f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_0.JPEG\tn03444034\t0\t32\t44\t62\n",
            "val_1.JPEG\tn04067472\t52\t55\t57\t59\n",
            "val_2.JPEG\tn04070727\t4\t0\t60\t55\n",
            "val_3.JPEG\tn02808440\t3\t3\t63\t63\n",
            "val_4.JPEG\tn02808440\t9\t27\t63\t48\n",
            "val_5.JPEG\tn04399382\t7\t0\t59\t63\n",
            "val_6.JPEG\tn04179913\t0\t0\t63\t56\n",
            "val_7.JPEG\tn02823428\t5\t0\t57\t63\n",
            "val_8.JPEG\tn04146614\t0\t31\t60\t60\n",
            "val_9.JPEG\tn02226429\t0\t3\t63\t57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main_patch_vit.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOi10a5zwTGo",
        "outputId": "8b7ef587-76d2-4f3e-92c2-0320b5bd93c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/content/TrojViT/models/DeiT.py:61: UserWarning: Overwriting deit_tiny_patch16_224 in registry with models.DeiT.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_tiny_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:76: UserWarning: Overwriting deit_small_patch16_224 in registry with models.DeiT.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_small_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:91: UserWarning: Overwriting deit_base_patch16_224 in registry with models.DeiT.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:106: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with models.DeiT.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:121: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with models.DeiT.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_small_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:136: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with models.DeiT.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:151: UserWarning: Overwriting deit_base_patch16_384 in registry with models.DeiT.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_patch16_384(pretrained=False, **kwargs):\n",
            "/content/TrojViT/models/DeiT.py:166: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with models.DeiT.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_distilled_patch16_384(pretrained=False, **kwargs):\n",
            "Tiny ImageNet already downloaded!\n",
            "Tiny ImageNet already extracted!\n",
            "Processing Tiny ImageNet validation dataset...\n",
            "86567656\n",
            "DataParallel(\n",
            "  (module): VisionTransformer(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "    (patch_drop): Identity()\n",
            "    (norm_pre): Identity()\n",
            "    (blocks): Sequential(\n",
            "      (0): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): Identity()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): Identity()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): Identity()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): Identity()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): Identity()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): Identity()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): Identity()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): Identity()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): Identity()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): Identity()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): Identity()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): Identity()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): Identity()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): Identity()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): Identity()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): Identity()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): Identity()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): Identity()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (9): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): Identity()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): Identity()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (10): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): Identity()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): Identity()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "      (11): Block(\n",
            "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (attn): Attention(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (q_norm): Identity()\n",
            "          (k_norm): Identity()\n",
            "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls1): Identity()\n",
            "        (drop_path1): Identity()\n",
            "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "        (mlp): Mlp(\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (act): GELU(approximate='none')\n",
            "          (drop1): Dropout(p=0.0, inplace=False)\n",
            "          (norm): Identity()\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (drop2): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (ls2): Identity()\n",
            "        (drop_path2): Identity()\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "    (fc_norm): Identity()\n",
            "    (head_drop): Dropout(p=0.0, inplace=False)\n",
            "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "Got 3315/10000 correct (33.15%) on the trojan data\n",
            "Got 0/10000 correct (0.00%) on the clean data\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "Starting epoch 1 / 200\n",
            "loss: tensor(6.2484, device='cuda:0')\n",
            "Starting epoch 2 / 200\n",
            "loss: tensor(5.2953, device='cuda:0')\n",
            "Starting epoch 3 / 200\n",
            "loss: tensor(4.6543, device='cuda:0')\n",
            "Starting epoch 4 / 200\n",
            "loss: tensor(5.0261, device='cuda:0')\n",
            "Starting epoch 5 / 200\n",
            "loss: tensor(4.9511, device='cuda:0')\n",
            "Starting epoch 6 / 200\n",
            "loss: tensor(4.7690, device='cuda:0')\n",
            "Starting epoch 7 / 200\n",
            "loss: tensor(5.0237, device='cuda:0')\n",
            "Starting epoch 8 / 200\n",
            "loss: tensor(5.0100, device='cuda:0')\n",
            "Starting epoch 9 / 200\n",
            "loss: tensor(4.5718, device='cuda:0')\n",
            "Starting epoch 10 / 200\n",
            "loss: tensor(4.9817, device='cuda:0')\n",
            "Starting epoch 11 / 200\n",
            "loss: tensor(4.8376, device='cuda:0')\n",
            "Starting epoch 12 / 200\n",
            "loss: tensor(4.8137, device='cuda:0')\n",
            "Starting epoch 13 / 200\n",
            "loss: tensor(4.8362, device='cuda:0')\n",
            "Starting epoch 14 / 200\n",
            "loss: tensor(4.8015, device='cuda:0')\n",
            "Starting epoch 15 / 200\n",
            "loss: tensor(4.8103, device='cuda:0')\n",
            "Starting epoch 16 / 200\n",
            "loss: tensor(4.7205, device='cuda:0')\n",
            "Starting epoch 17 / 200\n",
            "loss: tensor(4.6998, device='cuda:0')\n",
            "Starting epoch 18 / 200\n",
            "loss: tensor(5.2921, device='cuda:0')\n",
            "Starting epoch 19 / 200\n",
            "loss: tensor(4.8660, device='cuda:0')\n",
            "Starting epoch 20 / 200\n",
            "loss: tensor(4.7135, device='cuda:0')\n",
            "Starting epoch 21 / 200\n",
            "loss: tensor(4.9645, device='cuda:0')\n",
            "Starting epoch 22 / 200\n",
            "loss: tensor(4.8967, device='cuda:0')\n",
            "Starting epoch 23 / 200\n",
            "loss: tensor(4.7132, device='cuda:0')\n",
            "Starting epoch 24 / 200\n",
            "loss: tensor(4.7423, device='cuda:0')\n",
            "Starting epoch 25 / 200\n",
            "loss: tensor(4.8229, device='cuda:0')\n",
            "Starting epoch 26 / 200\n",
            "loss: tensor(4.7638, device='cuda:0')\n",
            "Starting epoch 27 / 200\n",
            "loss: tensor(5.0324, device='cuda:0')\n",
            "Starting epoch 28 / 200\n",
            "loss: tensor(4.9009, device='cuda:0')\n",
            "Starting epoch 29 / 200\n",
            "loss: tensor(4.9216, device='cuda:0')\n",
            "Starting epoch 30 / 200\n",
            "loss: tensor(4.7018, device='cuda:0')\n",
            "Starting epoch 31 / 200\n",
            "loss: tensor(4.7602, device='cuda:0')\n",
            "Starting epoch 32 / 200\n",
            "loss: tensor(4.6971, device='cuda:0')\n",
            "Starting epoch 33 / 200\n",
            "loss: tensor(4.8168, device='cuda:0')\n",
            "Starting epoch 34 / 200\n",
            "loss: tensor(4.4356, device='cuda:0')\n",
            "Starting epoch 35 / 200\n",
            "loss: tensor(4.7002, device='cuda:0')\n",
            "Starting epoch 36 / 200\n",
            "loss: tensor(4.7728, device='cuda:0')\n",
            "Starting epoch 37 / 200\n",
            "loss: tensor(4.7161, device='cuda:0')\n",
            "Starting epoch 38 / 200\n",
            "loss: tensor(4.8055, device='cuda:0')\n",
            "Starting epoch 39 / 200\n",
            "loss: tensor(4.7375, device='cuda:0')\n",
            "Starting epoch 40 / 200\n",
            "loss: tensor(4.8616, device='cuda:0')\n",
            "Got 9973/10000 correct (99.73%) on the trojan data\n",
            "Got 2/10000 correct (0.02%) on the clean data\n",
            "Starting epoch 41 / 200\n",
            "loss: tensor(4.7732, device='cuda:0')\n",
            "Starting epoch 42 / 200\n",
            "loss: tensor(4.7518, device='cuda:0')\n",
            "Starting epoch 43 / 200\n",
            "loss: tensor(4.6455, device='cuda:0')\n",
            "Starting epoch 44 / 200\n",
            "loss: tensor(4.6226, device='cuda:0')\n",
            "Starting epoch 45 / 200\n",
            "loss: tensor(4.9046, device='cuda:0')\n",
            "Starting epoch 46 / 200\n",
            "loss: tensor(4.4886, device='cuda:0')\n",
            "Starting epoch 47 / 200\n",
            "loss: tensor(4.6980, device='cuda:0')\n",
            "Starting epoch 48 / 200\n",
            "loss: tensor(4.5579, device='cuda:0')\n",
            "Starting epoch 49 / 200\n",
            "loss: tensor(4.7989, device='cuda:0')\n",
            "Starting epoch 50 / 200\n",
            "loss: tensor(4.7280, device='cuda:0')\n",
            "Starting epoch 51 / 200\n",
            "loss: tensor(4.6917, device='cuda:0')\n",
            "Starting epoch 52 / 200\n",
            "loss: tensor(5.0540, device='cuda:0')\n",
            "Starting epoch 53 / 200\n",
            "loss: tensor(4.7047, device='cuda:0')\n",
            "Starting epoch 54 / 200\n",
            "loss: tensor(4.9244, device='cuda:0')\n",
            "Starting epoch 55 / 200\n",
            "loss: tensor(4.9862, device='cuda:0')\n",
            "Starting epoch 56 / 200\n",
            "loss: tensor(4.4537, device='cuda:0')\n",
            "Starting epoch 57 / 200\n",
            "loss: tensor(4.6409, device='cuda:0')\n",
            "Starting epoch 58 / 200\n",
            "loss: tensor(4.7640, device='cuda:0')\n",
            "Starting epoch 59 / 200\n",
            "loss: tensor(4.7180, device='cuda:0')\n",
            "Starting epoch 60 / 200\n",
            "loss: tensor(4.5265, device='cuda:0')\n",
            "Starting epoch 61 / 200\n",
            "loss: tensor(4.5502, device='cuda:0')\n",
            "Starting epoch 62 / 200\n",
            "loss: tensor(4.7670, device='cuda:0')\n",
            "Starting epoch 63 / 200\n",
            "loss: tensor(4.7533, device='cuda:0')\n",
            "Starting epoch 64 / 200\n",
            "loss: tensor(4.8007, device='cuda:0')\n",
            "Starting epoch 65 / 200\n",
            "loss: tensor(5.0251, device='cuda:0')\n",
            "Starting epoch 66 / 200\n",
            "loss: tensor(4.6907, device='cuda:0')\n",
            "Starting epoch 67 / 200\n",
            "loss: tensor(4.9702, device='cuda:0')\n",
            "Starting epoch 68 / 200\n",
            "loss: tensor(4.8145, device='cuda:0')\n",
            "Starting epoch 69 / 200\n",
            "loss: tensor(4.8538, device='cuda:0')\n",
            "Starting epoch 70 / 200\n",
            "loss: tensor(4.9208, device='cuda:0')\n",
            "Starting epoch 71 / 200\n",
            "loss: tensor(4.6178, device='cuda:0')\n",
            "Starting epoch 72 / 200\n",
            "loss: tensor(4.5763, device='cuda:0')\n",
            "Starting epoch 73 / 200\n",
            "loss: tensor(4.5775, device='cuda:0')\n",
            "Starting epoch 74 / 200\n",
            "loss: tensor(4.5903, device='cuda:0')\n",
            "Starting epoch 75 / 200\n",
            "loss: tensor(4.6309, device='cuda:0')\n",
            "Starting epoch 76 / 200\n",
            "loss: tensor(4.4528, device='cuda:0')\n",
            "Starting epoch 77 / 200\n",
            "loss: tensor(4.8337, device='cuda:0')\n",
            "Starting epoch 78 / 200\n",
            "loss: tensor(4.5428, device='cuda:0')\n",
            "Starting epoch 79 / 200\n",
            "loss: tensor(4.6356, device='cuda:0')\n",
            "Starting epoch 80 / 200\n",
            "loss: tensor(4.7885, device='cuda:0')\n",
            "Got 9980/10000 correct (99.80%) on the trojan data\n",
            "Got 2/10000 correct (0.02%) on the clean data\n",
            "Starting epoch 81 / 200\n",
            "loss: tensor(4.7278, device='cuda:0')\n",
            "Starting epoch 82 / 200\n",
            "loss: tensor(4.4567, device='cuda:0')\n",
            "Starting epoch 83 / 200\n",
            "loss: tensor(4.6325, device='cuda:0')\n",
            "Starting epoch 84 / 200\n",
            "loss: tensor(4.6710, device='cuda:0')\n",
            "Starting epoch 85 / 200\n",
            "loss: tensor(4.4078, device='cuda:0')\n",
            "Starting epoch 86 / 200\n",
            "loss: tensor(4.6873, device='cuda:0')\n",
            "Starting epoch 87 / 200\n",
            "loss: tensor(4.5852, device='cuda:0')\n",
            "Starting epoch 88 / 200\n",
            "loss: tensor(4.8420, device='cuda:0')\n",
            "Starting epoch 89 / 200\n",
            "loss: tensor(4.5899, device='cuda:0')\n",
            "Starting epoch 90 / 200\n",
            "loss: tensor(4.6352, device='cuda:0')\n",
            "Starting epoch 91 / 200\n",
            "loss: tensor(4.3570, device='cuda:0')\n",
            "Starting epoch 92 / 200\n",
            "loss: tensor(4.9433, device='cuda:0')\n",
            "Starting epoch 93 / 200\n",
            "loss: tensor(4.7531, device='cuda:0')\n",
            "Starting epoch 94 / 200\n",
            "loss: tensor(4.7130, device='cuda:0')\n",
            "Starting epoch 95 / 200\n",
            "loss: tensor(4.6069, device='cuda:0')\n",
            "Starting epoch 96 / 200\n",
            "loss: tensor(4.6451, device='cuda:0')\n",
            "Starting epoch 97 / 200\n",
            "loss: tensor(4.6898, device='cuda:0')\n",
            "Starting epoch 98 / 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J3YUko1bwnoE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}